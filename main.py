from astrbot.api.message_components import *
from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
import aiohttp
import urllib.parse
from bs4 import BeautifulSoup
import time
import asyncio
import re
import random

@register("bot_vod", "appale", "è§†é¢‘æœç´¢åŠåˆ†é¡µåŠŸèƒ½ï¼ˆå‘½ä»¤ï¼š/vod /vodd /ç¿»é¡µï¼‰", "3.0.0")
class VideoSearchPlugin(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        self.api_url_vod = config.get("api_url_vod", "").split(',')
        self.api_url_18 = config.get("api_url_18", "").split(',')
        self.records = int(config.get("records", "3"))
        self.user_pages = {}
        self.MAX_PAGE_LENGTH = 1000
        self.REQUEST_TIMEOUT = 15
        self.MAX_RETRIES = 2

    def _get_user_identity(self, event: AstrMessageEvent) -> str:
        """ç”Ÿæˆå”¯ä¸€ç”¨æˆ·æ ‡è¯†"""
        try:
            return f"{event.platform}-{event.get_sender_id()}" if hasattr(event, 'get_sender_id') else f"{event.platform}-{hash(event)}"
        except Exception as e:
            self.context.logger.error(f"ç”¨æˆ·æ ‡è¯†ç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"unknown-{int(time.time())}"

    async def _fetch_api(self, url: str, keyword: str, is_adult: bool = False) -> dict:
        """æ‰§è¡ŒAPIè¯·æ±‚ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": urllib.parse.urlparse(url).scheme + "://" + urllib.parse.urlparse(url).netloc + "/"
        }

        for attempt in range(self.MAX_RETRIES):
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        url=url,
                        params={"wd": keyword} if not is_adult else {"q": keyword},
                        headers=headers,
                        timeout=self.REQUEST_TIMEOUT,
                        proxy=self.config.get("proxy") if not is_adult else None
                    ) as response:
                        if response.status != 200:
                            continue

                        content = await response.text()
                        soup = BeautifulSoup(content, 'html.parser')

                        # è§£ææ­£å¸¸èµ„æº
                        if not is_adult:
                            items = soup.select('div.module-search-item')
                            return {
                                "success": True,
                                "data": [{
                                    "title": item.select_one('div.video-info-header a').get_text(strip=True),
                                    "urls": [{
                                        "url": a['href'],
                                        "name": a.get_text(strip=True)
                                    } for a in item.select('div.module-item-cover a')[:self.records]]
                                } for item in items]
                            }
                        # è§£æç‰¹æ®Šèµ„æº
                        else:
                            items = soup.select('div.tg-item')
                            return {
                                "success": True,
                                "data": [{
                                    "title": item.select_one('div.tg-info').get_text(strip=True),
                                    "urls": [{
                                        "url": item.select_one('a')['href'],
                                        "name": item.select_one('img')['alt'].strip()
                                    }][:self.records]
                                } for item in items]
                            }
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                self.context.logger.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ˆå°è¯•{attempt+1}ï¼‰: {str(e)}")
                if attempt < self.MAX_RETRIES - 1:
                    await asyncio.sleep(1 + random.random())
        return {"success": False}

    def _build_content_blocks(self, results: list) -> list:
        """æ„å»ºåˆ†é¡µå†…å®¹å—ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        blocks = []
        for result in results:
            title = f"ğŸ” {result['title']}"
            urls = [f"   ğŸ¬ {url['url']} ({url['name']})" for url in result['urls']]
            
            # è®¡ç®—å—æ€»é•¿åº¦ï¼ˆåŒ…å«æ¢è¡Œç¬¦ï¼‰
            block_lines = [title] + urls
            total_length = sum(len(line) + 1 for line in block_lines) - 1  # æœ€åä¸€è¡Œä¸åŠ æ¢è¡Œç¬¦
            
            blocks.append({
                "type": "resource_block",
                "lines": block_lines,
                "length": total_length,
                "title": title,
                "url_count": len(urls)
            })
        return blocks

    def _generate_pages(self, header: list, blocks: list) -> list:
        """åˆ†é¡µç”Ÿæˆå™¨ï¼ˆå®Œæ•´ç®—æ³•ï¼‰"""
        pages = []
        current_page = []
        current_length = sum(len(line) + 1 for line in header)  # é¡µçœ‰é•¿åº¦
        
        # é¡µè„šæ¨¡æ¿
        footer_template = [
            "â”" * 30,
            "ğŸ“– ç¬¬ {current_page}/{total_pages} é¡µ",
            "â³ æœ‰æ•ˆæœŸè‡³ {expire_time}ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰",
            "ğŸ”§ ä½¿ç”¨ /ç¿»é¡µ [é¡µç ] åˆ‡æ¢é¡µé¢",
            "â”" * 30
        ]
        footer_length = sum(len(line.format(current_page=1, total_pages=1, expire_time="00:00")) + 1 for line in footer_template) - 1
        
        for block in blocks:
            required_space = block['length'] + 2  # å—å‰åç©ºè¡Œ
            test_length = current_length + required_space + footer_length
            
            # æƒ…å†µ1ï¼šå¯ä»¥å®Œæ•´æ”¾å…¥å½“å‰é¡µ
            if test_length <= self.MAX_PAGE_LENGTH:
                current_page.append(block)
                current_length += required_space
                continue
                
            # æƒ…å†µ2ï¼šéœ€è¦æ–°å»ºé¡µé¢
            if current_page:
                # ç”Ÿæˆå®é™…é¡µé¢å†…å®¹
                page_content = []
                for blk in current_page:
                    page_content.extend(blk['lines'])
                    page_content.append('')  # å—é—´ç©ºè¡Œ
                page_content.pop()  # ç§»é™¤æœ€åç©ºè¡Œ
                
                # ç”Ÿæˆå®Œæ•´é¡µé¢
                expire_time = time.strftime("%H:%M", time.localtime(time.time() + 300 + 8*3600))
                footer = [line.format(
                    current_page=len(pages)+1,
                    total_pages="TBD",
                    expire_time=expire_time
                ) for line in footer_template]
                
                full_page = '\n'.join(header + page_content + footer)
                pages.append(full_page)
                current_page = []
                current_length = sum(len(line) + 1 for line in header)
                
            # å¤„ç†è¶…å¤§å—ï¼ˆå•ç‹¬æˆé¡µï¼‰
            test_length = sum(len(line) + 1 for line in header) + block['length'] + footer_length
            if test_length > self.MAX_PAGE_LENGTH:
                # æ‰§è¡Œæˆªæ–­å¤„ç†
                truncated_lines = [block['title'], "   âš ï¸ éƒ¨åˆ†ç»“æœå·²æŠ˜å ï¼ˆå®Œæ•´åˆ—è¡¨è¯·è®¿é—®ç½‘ç«™ï¼‰"]
                for url_line in block['lines'][1:]:
                    if sum(len(line) + 1 for line in truncated_lines) + footer_length + 50 < self.MAX_PAGE_LENGTH:
                        truncated_lines.append(url_line)
                current_page = [{
                    "type": "truncated_block",
                    "lines": truncated_lines,
                    "length": sum(len(line) + 1 for line in truncated_lines) - 1
                }]
            else:
                current_page.append(block)
            current_length = sum(len(line) + 1 for line in header) + current_page[0]['length'] + 2
        
        # å¤„ç†æœ€åä¸€é¡µ
        if current_page:
            page_content = []
            for blk in current_page:
                page_content.extend(blk['lines'])
                page_content.append('')
            page_content.pop()
            
            expire_time = time.strftime("%H:%M", time.localtime(time.time() + 300 + 8*3600))
            footer = [line.format(
                current_page=len(pages)+1,
                total_pages="TBD",
                expire_time=expire_time
            ) for line in footer_template]
            
            full_page = '\n'.join(header + page_content + footer)
            pages.append(full_page)
        
        # æ›´æ–°æ€»é¡µæ•°
        for idx in range(len(pages)):
            pages[idx] = pages[idx].replace("TBD", str(len(pages)))
        
        return pages

    @filter.command("vod")
    async def search_normal(self, event: AstrMessageEvent, text: str):
        """æ™®é€šèµ„æºæœç´¢ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        keyword = text.strip()
        if not keyword:
            yield event.plain_result("ğŸ” è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š/vod æµæµªåœ°çƒ")
            return
        
        results = []
        total_apis = len(self.api_url_vod)
        successful_apis = 0
        
        async with event.loading("ğŸ” æœç´¢ä¸­..."):
            for api_url in self.api_url_vod:
                try:
                    response = await self._fetch_api(api_url, keyword)
                    if response['success'] and response['data']:
                        results.extend(response['data'])
                        successful_apis += 1
                except Exception as e:
                    self.context.logger.error(f"APIå¤„ç†å¤±è´¥ï¼š{str(e)}")
        
        if results:
            header = [
                f"ğŸ” æœç´¢ {total_apis} ä¸ªæºï½œæˆåŠŸ {successful_apis} ä¸ª",
                f"ğŸ“š æ‰¾åˆ° {sum(len(res['urls']) for res in results)} æ¡èµ„æº",
                "â”" * 30
            ]
            
            # æ„å»ºåˆ†é¡µ
            blocks = self._build_content_blocks(results)
            pages = self._generate_pages(header, blocks)
            
            # å­˜å‚¨åˆ†é¡µçŠ¶æ€
            user_id = self._get_user_identity(event)
            self.user_pages[user_id] = {
                "pages": pages,
                "timestamp": time.time(),
                "total_pages": len(pages),
                "search_type": "normal"
            }
            
            yield event.plain_result(pages[0])
        else:
            yield event.plain_result(f"âš ï¸ æœªæ‰¾åˆ°ã€{keyword}ã€‘ç›¸å…³èµ„æº\nå°è¯•æ›´æ¢å…³é”®è¯æˆ–ç¨åé‡è¯•")

    @filter.command("vodd")
    async def search_adult(self, event: AstrMessageEvent, text: str):
        """ç‰¹æ®Šèµ„æºæœç´¢ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        if not self.config.get("enable_adult"):
            yield event.plain_result("â›” æ­¤åŠŸèƒ½æš‚æœªå¼€æ”¾")
            return
        
        keyword = text.strip()
        if not keyword:
            yield event.plain_result("ğŸ” è¯·è¾“å…¥æœç´¢å…³é”®è¯")
            return
        
        results = []
        successful_apis = 0
        
        async with event.loading("ğŸ” ç‰¹æ®Šæœç´¢ä¸­..."):
            for api_url in self.api_url_18:
                try:
                    response = await self._fetch_api(api_url, keyword, is_adult=True)
                    if response['success'] and response['data']:
                        results.extend(response['data'])
                        successful_apis += 1
                except Exception as e:
                    self.context.logger.error(f"ç‰¹æ®ŠAPIå¤±è´¥ï¼š{str(e)}")
        
        if results:
            header = [
                f"ğŸ” æœç´¢ {len(self.api_url_18)} ä¸ªæºï½œæˆåŠŸ {successful_apis} ä¸ª",
                f"ğŸ“š æ‰¾åˆ° {sum(len(res['urls']) for res in results)} æ¡ç‰¹æ®Šèµ„æº",
                "âš ï¸ æœ¬ç»“æœä¿ç•™5åˆ†é’Ÿ",
                "â”" * 30
            ]
            
            blocks = self._build_content_blocks(results)
            pages = self._generate_pages(header, blocks)
            
            user_id = self._get_user_identity(event)
            self.user_pages[user_id] = {
                "pages": pages,
                "timestamp": time.time(),
                "total_pages": len(pages),
                "search_type": "adult"
            }
            
            yield event.plain_result(pages[0])
        else:
            yield event.plain_result(f"âš ï¸ æœªæ‰¾åˆ°ã€{keyword}ã€‘ç›¸å…³ç‰¹æ®Šèµ„æº")

    @filter.command("ç¿»é¡µ")
    async def paginate(self, event: AstrMessageEvent, text: str):
        """åˆ†é¡µå¤„ç†ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        user_id = self._get_user_identity(event)
        page_data = self.user_pages.get(user_id)
        
        # æœ‰æ•ˆæ€§æ£€æŸ¥
        if not page_data or time.time() - page_data['timestamp'] > 300:
            yield event.plain_result("â³ æœç´¢ç»“æœå·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢")
            return
        
        # æ™ºèƒ½é¡µç è§£æ
        text = text.strip().lower()
        cn_num_map = {'ä¸€':1, 'äºŒ':2, 'ä¸‰':3, 'å››':4, 'äº”':5, 'æœ«': page_data['total_pages']}
        match = re.match(r"^(?:ç¬¬|p)?(\d+|[\u4e00-\u9fa5]{1,3})[é¡µ]?$", text)
        
        page_num = 0
        if match:
            raw = match.group(1)
            if raw in cn_num_map:
                page_num = cn_num_map[raw]
            else:
                try:
                    page_num = int(raw)
                except:
                    pass
        else:
            try:
                page_num = int(text)
            except:
                pass
        
        # è¾¹ç•Œæ£€æŸ¥
        if not 1 <= page_num <= page_data['total_pages']:
            help_msg = [
                f"âš ï¸ æ— æ•ˆé¡µç ï¼ˆ1-{page_data['total_pages']}ï¼‰",
                "æ”¯æŒæ ¼å¼ï¼š",
                "Â· æ•°å­—ï¼š2",
                "Â· ä¸­æ–‡ï¼šäºŒ",
                "Â· å¸¦é¡µç ï¼šç¬¬3é¡µ",
                f"å½“å‰å…± {page_data['total_pages']} é¡µ"
            ]
            yield event.plain_result('\n'.join(help_msg))
            return
        
        # æ›´æ–°æœ‰æ•ˆæœŸ
        new_expire = time.time() + 300
        new_time_str = time.strftime("%H:%M", time.localtime(new_expire + 8*3600))
        updated_page = re.sub(
            r'æœ‰æ•ˆæœŸè‡³ \d{2}:\d{2}',
            f'æœ‰æ•ˆæœŸè‡³ {new_time_str}',
            page_data['pages'][page_num-1]
        )
        
        # æ›´æ–°å­˜å‚¨æ—¶é—´
        self.user_pages[user_id]['timestamp'] = new_expire - 300
        
        yield event.plain_result(updated_page)

    async def _cleanup_task(self):
        """å®šæ—¶æ¸…ç†ä»»åŠ¡ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        while True:
            now = time.time()
            to_remove = []
            
            for user_id, data in self.user_pages.items():
                if now - data['timestamp'] > 300 or data['total_pages'] > 50:
                    to_remove.append(user_id)
            
            for user_id in to_remove:
                del self.user_pages[user_id]
                self.context.logger.info(f"æ¸…ç†ç”¨æˆ·åˆ†é¡µæ•°æ®ï¼š{user_id}")
            
            await asyncio.sleep(60)

    async def activate(self):
        """æ¿€æ´»æ’ä»¶ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        await super().activate()
        asyncio.create_task(self._cleanup_task())
