from astrbot.api.message_components import *
from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
import aiohttp
import urllib.parse
from bs4 import BeautifulSoup
import time
import asyncio

@register("bot_vod", "appale", "è§†é¢‘æœç´¢åŠåˆ†é¡µåŠŸèƒ½ï¼ˆå‘½ä»¤ï¼š/vod /vodd /vodpageï¼‰", "1.2")
class VideoSearchPlugin(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        self.api_url_vod = config.get("api_url_vod", "").split(',')
        self.api_url_18 = config.get("api_url_18", "").split(',')
        self.records = int(config.get("records", "3"))
        self.user_pages = {}  # ç”¨æˆ·åˆ†é¡µæ•°æ®å­˜å‚¨

    def _get_user_identity(self, event: AstrMessageEvent) -> str:
        """å®‰å…¨è·å–ç”¨æˆ·å”¯ä¸€æ ‡è¯†ï¼ˆæ ¸å¿ƒä¿®å¤ç‚¹ï¼‰"""
        try:
            # æ ‡å‡†æ–¹æ³•è·å–ç”¨æˆ·ID
            if hasattr(event, 'get_sender_id'):
                return event.get_sender_id()
            # å…¼å®¹æ—§ç‰ˆå¾®ä¿¡å¹³å°äº‹ä»¶æ ¼å¼
            elif hasattr(event, 'user') and hasattr(event.user, 'openid'):
                return f"wechat-{event.user.openid}"
            # é€šç”¨å¤‡é€‰æ–¹æ¡ˆ
            return f"{event.platform}-{hash(event)}"
        except Exception as e:
            self.context.logger.error(f"è·å–ç”¨æˆ·æ ‡è¯†å¤±è´¥: {str(e)}")
            return "unknown_user"

    async def _common_handler(self, event: AstrMessageEvent, api_urls: list, keyword: str):
        """æ ¸å¿ƒæœç´¢é€»è¾‘ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        user_id = self._get_user_identity(event)
        total_attempts = len(api_urls)
        successful_apis = 0
        grouped_results = {}
        ordered_titles = []
        
        # APIè¯·æ±‚å¤„ç†
        for api_url in api_urls:
            api_url = api_url.strip()
            if not api_url:
                continue

            try:
                encoded_keyword = urllib.parse.quote(keyword)
                query_url = f"{api_url}?ac=videolist&wd={encoded_keyword}"
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(query_url, timeout=15) as response:
                        if response.status != 200:
                            continue
                            
                        # è§£æHTMLå†…å®¹
                        html_content = await response.text()
                        soup = BeautifulSoup(html_content, 'html.parser')
                        video_items = soup.select('rss list video')[:self.records]
                        
                        # å¤„ç†è§†é¢‘é¡¹
                        for item in video_items:
                            title = item.select_one('name').text.strip() if item.select_one('name') else "æœªçŸ¥æ ‡é¢˜"
                            for dd in item.select('dl > dd'):
                                for url in dd.text.split('#'):
                                    if (url := url.strip()):
                                        if title not in grouped_results:
                                            grouped_results[title] = []
                                            ordered_titles.append(title)
                                        grouped_results[title].append(url)
                        successful_apis += 1
                        
            except Exception as e:
                self.context.logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
                continue

        # æ„å»ºç»“æœåˆ—è¡¨
        result_lines = []
        total_videos = sum(len(urls) for urls in grouped_results.values())
        m3u8_flags = []
        
        for idx, title in enumerate(ordered_titles, 1):
            urls = grouped_results.get(title, [])
            result_lines.append(f"{idx}. ã€{title}ã€‘")
            for url in urls:
                result_lines.append(f"   ğŸ¬ {url}")
                m3u8_flags.append(url.endswith('.m3u8'))

        # åˆ†é¡µå¤„ç†é€»è¾‘
        pages = []
        if result_lines:
            header_lines = [
                f"ğŸ” æœç´¢ {total_attempts} ä¸ªæºï½œæˆåŠŸ {successful_apis} ä¸ª",
                f"ğŸ“Š æ‰¾åˆ° {total_videos} æ¡èµ„æº",
                "â”" * 30
            ]
            footer_lines = [
                "â”" * 30,
                "ğŸ’¡ æ’­æ”¾æç¤ºï¼š",
                "1. ç§»åŠ¨ç«¯ç›´æ¥ç²˜è´´é“¾æ¥åˆ°æµè§ˆå™¨",
                "2. ç”µè„‘ç«¯æ¨èä½¿ç”¨PotPlayer/VLCæ’­æ”¾",
                "â”" * 30
            ]
            header_str = "\n".join(header_lines) + "\n"
            footer_str = "\n" + "\n".join(footer_lines)
            
            current_start = 0
            while current_start < len(result_lines):
                # å¯»æ‰¾åˆ†é¡µæ–­ç‚¹
                possible_ends = [
                    i for i, flag in enumerate(m3u8_flags[current_start:], current_start)
                    if flag
                ]
                if not possible_ends:
                    break
                
                # ç¡®å®šæœ€ä½³åˆ†é¡µä½ç½®
                best_end = None
                for end in reversed(possible_ends):
                    content_length = sum(
                        len(line) + 1 
                        for line in result_lines[current_start:end+1]
                    )
                    if (len(header_str) + content_length + len(footer_str)) <= 1000:
                        best_end = end
                        break
                best_end = best_end or possible_ends[0]
                
                # ç”Ÿæˆåˆ†é¡µå†…å®¹
                page_content = (
                    header_str +
                    "\n".join(result_lines[current_start:best_end+1]) +
                    footer_str
                )
                pages.append(page_content)
                current_start = best_end + 1

            # å­˜å‚¨åˆ†é¡µæ•°æ®
            self.user_pages[user_id] = {
                "pages": pages,
                "timestamp": time.time(),
                "total_pages": len(pages),
                "search_info": f"ğŸ” æœç´¢ {total_attempts} ä¸ªæºï½œæˆåŠŸ {successful_apis} ä¸ª\nğŸ“Š æ‰¾åˆ° {total_videos} æ¡èµ„æº"
            }
            yield event.plain_result(pages[0])
        else:
            yield event.plain_result(f"ğŸ” æœç´¢ {total_attempts} ä¸ªæºï½œæˆåŠŸ {successful_apis} ä¸ª\n{'â”'*30}\næœªæ‰¾åˆ°ç›¸å…³èµ„æº")

    @filter.command("vod")
    async def search_normal(self, event: AstrMessageEvent, text: str):
        """æ™®é€šè§†é¢‘æœç´¢"""
        if not self.api_url_vod:
            yield event.plain_result("âš ï¸ æ™®é€šè§†é¢‘æœåŠ¡æœªå¯ç”¨")
            return
        async for msg in self._common_handler(event, self.api_url_vod, text):
            yield msg

    @filter.command("vodd")
    async def search_adult(self, event: AstrMessageEvent, text: str):
        """æˆäººå†…å®¹æœç´¢"""
        if not self.api_url_18:
            yield event.plain_result("ğŸ” æˆäººå†…å®¹æœåŠ¡æœªå¯ç”¨")
            return
        async for msg in self._common_handler(event, self.api_url_18, text):
            yield msg

    @filter.command("vodpage")
    async def paginate_results(self, event: AstrMessageEvent, text: str):
        """åˆ†é¡µæŸ¥çœ‹ç»“æœ"""
        user_id = self._get_user_identity(event)
        page_data = self.user_pages.get(user_id)

        # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
        if not page_data or (time.time() - page_data["timestamp"]) > 300:
            yield event.plain_result("â³ æœç´¢ç»“æœå·²è¿‡æœŸï¼ˆæœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼‰ï¼Œè¯·é‡æ–°æœç´¢")
            return

        # è§£æé¡µç 
        try:
            page_num = int(text.strip())
            if page_num < 1 or page_num > page_data["total_pages"]:
                raise ValueError
        except ValueError:
            yield event.plain_result(f"âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆé¡µç ï¼ˆ1-{page_data['total_pages']}ï¼‰")
            return

        # æ„å»ºåˆ†é¡µæ¶ˆæ¯
        page_content = page_data["pages"][page_num-1]
        new_footer = [
            "â”" * 30,
            f"ğŸ“‘ ç¬¬ {page_num}/{page_data['total_pages']} é¡µ",
            f"â° æœ‰æ•ˆæœŸè‡³ {time.strftime('%H:%M', time.localtime(page_data['timestamp'] + 300))}",
            "â”" * 30
        ]
        
        # æ›¿æ¢footerå†…å®¹
        content_lines = page_content.split("\n")
        content_lines[-6:-3] = new_footer  # æ›¿æ¢åŸæœ‰footeréƒ¨åˆ†
        
        yield event.plain_result("\n".join(content_lines))

    async def _clean_expired_records(self):
        """åå°æ¸…ç†ä»»åŠ¡"""
        while True:
            now = time.time()
            expired_users = [
                uid for uid, data in self.user_pages.items()
                if now - data["timestamp"] > 300
            ]
            for uid in expired_users:
                del self.user_pages[uid]
            await asyncio.sleep(60)

    async def activate(self):
        """å¯åŠ¨æ’ä»¶"""
        await super().activate()
        asyncio.create_task(self._clean_expired_records())
